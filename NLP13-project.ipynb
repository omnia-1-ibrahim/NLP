{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8zWEqM3_KXt",
    "outputId": "7c1df7d4-44ac-44e6-cbdf-337a725a0259"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import emoji\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import PorterStemmer\n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Concatenate, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GNQiuRmw_OBH"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\Dell\\Downloads\\archive (3)\\train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MDBbJZTy_ZK8",
    "outputId": "681c2a7b-249e-4e66-f247-4423410d009d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "OpXX1xn4_by9",
    "outputId": "c49a592a-f00b-4313-d7aa-f80151d19b16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description_x</th>\n",
       "      <th>description_y</th>\n",
       "      <th>ticker_x</th>\n",
       "      <th>ticker_y</th>\n",
       "      <th>same_security</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>first trust dow jones internet</td>\n",
       "      <td>first trust dj internet idx</td>\n",
       "      <td>FDN</td>\n",
       "      <td>FDN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>schwab intl large company index etf</td>\n",
       "      <td>schwab strategic tr fundamental intl large co ...</td>\n",
       "      <td>FNDF</td>\n",
       "      <td>FNDF</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>vanguard small cap index adm</td>\n",
       "      <td>vanguard small-cap index fund inst</td>\n",
       "      <td>VSMAX</td>\n",
       "      <td>VSCIX</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>duke energy corp new com new isin #us4 sedol #...</td>\n",
       "      <td>duke energy corp new com new isin #us26441c204...</td>\n",
       "      <td>DUK</td>\n",
       "      <td>DUK</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>visa inc class a</td>\n",
       "      <td>visa inc.</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      description_x  \\\n",
       "0           0                     first trust dow jones internet   \n",
       "1           1                schwab intl large company index etf   \n",
       "2           2                       vanguard small cap index adm   \n",
       "3           3  duke energy corp new com new isin #us4 sedol #...   \n",
       "4           4                                   visa inc class a   \n",
       "\n",
       "                                       description_y ticker_x ticker_y  \\\n",
       "0                        first trust dj internet idx      FDN      FDN   \n",
       "1  schwab strategic tr fundamental intl large co ...     FNDF     FNDF   \n",
       "2                 vanguard small-cap index fund inst    VSMAX    VSCIX   \n",
       "3  duke energy corp new com new isin #us26441c204...      DUK      DUK   \n",
       "4                                          visa inc.        V        V   \n",
       "\n",
       "   same_security  \n",
       "0           True  \n",
       "1           True  \n",
       "2          False  \n",
       "3           True  \n",
       "4           True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvKP8rTw_dnB",
    "outputId": "9bcbb3fb-1ba7-4a60-c923-6bbf31bb2757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2142 entries, 0 to 2141\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Unnamed: 0     2142 non-null   int64 \n",
      " 1   description_x  2142 non-null   object\n",
      " 2   description_y  2142 non-null   object\n",
      " 3   ticker_x       2142 non-null   object\n",
      " 4   ticker_y       2142 non-null   object\n",
      " 5   same_security  2142 non-null   bool  \n",
      "dtypes: bool(1), int64(1), object(4)\n",
      "memory usage: 85.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bh1u-xBN_ghe",
    "outputId": "ebaef937-dee2-45bd-f7b7-00590d2c3542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0\n",
      "count  2142.000000\n",
      "mean   1070.500000\n",
      "std     618.486459\n",
      "min       0.000000\n",
      "25%     535.250000\n",
      "50%    1070.500000\n",
      "75%    1605.750000\n",
      "max    2141.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       0\n",
       "description_x    0\n",
       "description_y    0\n",
       "ticker_x         0\n",
       "ticker_y         0\n",
       "same_security    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.describe())\n",
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "GTlrS9u7_mR5",
    "outputId": "f72017d0-b49a-4fa4-81ab-de5eeee7cb60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same_security\n",
      "True     1613\n",
      "False     529\n",
      "Name: count, dtype: int64\n",
      "same_security\n",
      "True     75.303455\n",
      "False    24.696545\n",
      "Name: count, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='same_security'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data['same_security'].value_counts())\n",
    "print((data['same_security'].value_counts()/data['same_security'].count())*100)\n",
    "data['same_security'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gwA9x3Q__pO2",
    "outputId": "8ae39997-d8c0-40d9-870a-29e618ce8445"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FpTLYwm1_tbj",
    "outputId": "e9d8f50b-25ee-4bd8-a387-3f7235e22feb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique questions 2597\n",
      "Number of questions getting repeated 901\n"
     ]
    }
   ],
   "source": [
    "# Repeated Questions\n",
    "qid=pd.Series(data['description_x'].tolist()+data['description_y'].tolist())\n",
    "print('Number of unique questions',np.unique(qid).shape[0])\n",
    "x=qid.value_counts()>1\n",
    "print('Number of questions getting repeated',x[x].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "eKzb3pNI_wJC",
    "outputId": "0c068d14-998d-47cb-bbdf-4f0bea3c9735"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(qid.value_counts().values,bins=160)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "79YfTvvV_zj0"
   },
   "outputs": [],
   "source": [
    "data.rename(columns ={'description_x':'question1','description_y':'question2','same_security':'is_similar'},inplace=True)\n",
    "data.drop(columns=['ticker_x', 'ticker_y', data.columns[0]], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9LcXqx2_6RT",
    "outputId": "b088e647-bcad-4986-d083-23438f6ef66b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1713, 2), y_train shape: (1713,)\n",
      "X_test shape: (215, 2), y_test shape: (215,)\n",
      "X_val shape: (214, 2), y_val shape: (214,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = data[['question1', 'question2']], data['is_similar']\n",
    "\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "L-6QN6Q1_8ra",
    "outputId": "8792507b-5d3d-4482-a61c-69a059cdf031"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>novo nordisk a s adr</td>\n",
       "      <td>novo nordisk a/s-adr nvorepstg 1/2 cl b sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>spdr barclays high yieldbond etf</td>\n",
       "      <td>spdr barclays high yield bond (jnk)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>freeport mcmoran copper and gold inc</td>\n",
       "      <td>freeport-mcmoran inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>ishares msci switzerland capped</td>\n",
       "      <td>ishares msci switzerland capped etf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>philip morris international inc</td>\n",
       "      <td>philip morris intl com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 question1  \\\n",
       "905                   novo nordisk a s adr   \n",
       "1699      spdr barclays high yieldbond etf   \n",
       "1954  freeport mcmoran copper and gold inc   \n",
       "305        ishares msci switzerland capped   \n",
       "986        philip morris international inc   \n",
       "\n",
       "                                       question2  \n",
       "905   novo nordisk a/s-adr nvorepstg 1/2 cl b sh  \n",
       "1699         spdr barclays high yield bond (jnk)  \n",
       "1954                        freeport-mcmoran inc  \n",
       "305          ishares msci switzerland capped etf  \n",
       "986                       philip morris intl com  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "SeF-wm3tAANK",
    "outputId": "5689e240-f064-4027-b25e-4312dac1e33f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>ld abt sh drtn inc i</td>\n",
       "      <td>lord abbett short duration income fd cl f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>trp retirement 2050</td>\n",
       "      <td>t. rowe price 2050 fund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>wp carey inc com</td>\n",
       "      <td>w p carey and co. llc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>pimco income fund cl d</td>\n",
       "      <td>pimco incm cl d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>prudential jennison natural resources z</td>\n",
       "      <td>pru/j nat resrcs z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    question1  \\\n",
       "617                      ld abt sh drtn inc i   \n",
       "1978                      trp retirement 2050   \n",
       "554                          wp carey inc com   \n",
       "940                    pimco income fund cl d   \n",
       "49    prudential jennison natural resources z   \n",
       "\n",
       "                                      question2  \n",
       "617   lord abbett short duration income fd cl f  \n",
       "1978                    t. rowe price 2050 fund  \n",
       "554                      w p carey and co. llc.  \n",
       "940                             pimco incm cl d  \n",
       "49                           pru/j nat resrcs z  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FIH4Gcf8AEfY",
    "outputId": "35567695-4190-4cce-e0d4-1f990d7e6946"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>blackrock total return fund cl a</td>\n",
       "      <td>blackrock glbl opp eq tr f growth &amp; income fund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>energy transfer partners lp ut ltd</td>\n",
       "      <td>cheniere energy partners lp com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>facebook inc.</td>\n",
       "      <td>facebook inc class a common stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>vang tot bd mk is pl</td>\n",
       "      <td>vanguard total bond market index inv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>vanguard intl equity index fd inc ftse all-wor...</td>\n",
       "      <td>vanguard intl equity index</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question1  \\\n",
       "1288                   blackrock total return fund cl a   \n",
       "188                  energy transfer partners lp ut ltd   \n",
       "1656                                      facebook inc.   \n",
       "1657                               vang tot bd mk is pl   \n",
       "1677  vanguard intl equity index fd inc ftse all-wor...   \n",
       "\n",
       "                                            question2  \n",
       "1288  blackrock glbl opp eq tr f growth & income fund  \n",
       "188                   cheniere energy partners lp com  \n",
       "1656                facebook inc class a common stock  \n",
       "1657             vanguard total bond market index inv  \n",
       "1677                       vanguard intl equity index  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "TPOv_iq-AHJ8"
   },
   "outputs": [],
   "source": [
    "def get_entities(sent):\n",
    "    ent1 = \"\"\n",
    "    ent2 = \"\"\n",
    "\n",
    "    prv_tok_dep = \"\"  # dependency tag of the previous token in the sentence\n",
    "    prv_tok_text = \"\"  # the previous token in the sentence\n",
    "\n",
    "    prefix = \"\"\n",
    "    modifier = \"\"\n",
    "\n",
    "    for tok in nlp(sent):\n",
    "        # if the token is a punctuation mark, then move on to the next token\n",
    "        if tok.dep_ != \"punct\":\n",
    "            # check if the token is a compound word or not\n",
    "            if tok.dep_ == \"compound\":\n",
    "                prefix = tok.text\n",
    "                # if the previous word was also a 'compound', then add the current word to it\n",
    "                if prv_tok_dep == \"compound\":\n",
    "                    prefix = prv_tok_text + \" \" + tok.text\n",
    "            # check if the token is a modifier or not\n",
    "            if tok.dep_.endswith(\"mod\") == True:\n",
    "                modifier = tok.text\n",
    "                # if the previous word was also a 'compound', then add the current word to it\n",
    "                if prv_tok_dep == \"compound\":\n",
    "                    modifier = prv_tok_text + \" \" + tok.text\n",
    "            # check if the token is a subject\n",
    "            if tok.dep_.find(\"subj\") == True:\n",
    "                ent1 = modifier + \" \" + prefix + \" \" + tok.text\n",
    "                prefix = \"\"\n",
    "                modifier = \"\"\n",
    "                prv_tok_dep = \"\"\n",
    "                prv_tok_text = \"\"\n",
    "            # check if the token is an object\n",
    "            if tok.dep_.find(\"obj\") == True:\n",
    "                ent2 = modifier + \" \" + prefix + \" \" + tok.text\n",
    "            # update variables\n",
    "            prv_tok_dep = tok.dep_\n",
    "            prv_tok_text = tok.text\n",
    "\n",
    "    return [ent1.strip(), ent2.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "mE81ZrK5AMMX"
   },
   "outputs": [],
   "source": [
    "def clean_text(x):\n",
    "    text = re.sub('(\\d+)','',x)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "def remove_punct(x):\n",
    "    text_without_puct = [t for t in x if t not in string.punctuation]\n",
    "    text_without_puct = ''.join(text_without_puct)\n",
    "    return text_without_puct\n",
    "stemm = PorterStemmer()\n",
    "def stemmer(x):\n",
    "    tokens = word_tokenize(x)\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "EaIL1dxYAjIt"
   },
   "outputs": [],
   "source": [
    "def get_relation(sent):\n",
    "    doc = nlp(sent)\n",
    "\n",
    "    # Matcher class object\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    # Define the pattern\n",
    "    pattern = [{'DEP': 'ROOT'},\n",
    "               {'DEP': 'prep', 'OP': \"?\"},\n",
    "               {'DEP': 'agent', 'OP': \"?\"},\n",
    "               {'POS': 'ADJ', 'OP': \"?\"}]\n",
    "\n",
    "    # Wrap the pattern in a list when adding to the Matcher\n",
    "    matcher.add(\"matching_1\", [pattern])\n",
    "\n",
    "    matches = matcher(doc)\n",
    "    k = len(matches) - 1\n",
    "\n",
    "    span = doc[matches[k][1]:matches[k][2]]\n",
    "\n",
    "    return span.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rEoqadmQAmVL"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train['question1'] = X_train['question1'].apply(clean_text)\n",
    "X_train['question1'] = X_train['question1'].apply(remove_punct)\n",
    "X_train['question1'] = X_train['question1'].apply(stemmer)\n",
    "\n",
    "X_train['question2'] = X_train['question2'].apply(clean_text)\n",
    "X_train['question2'] = X_train['question2'].apply(remove_punct)\n",
    "X_train['question2'] = X_train['question2'].apply(stemmer)\n",
    "\n",
    "X_test['question1'] = X_test['question1'].apply(clean_text)\n",
    "X_test['question1'] = X_test['question1'].apply(remove_punct)\n",
    "X_test['question1'] = X_test['question1'].apply(stemmer)\n",
    "\n",
    "\n",
    "X_test['question2'] = X_test['question2'].apply(clean_text)\n",
    "X_test['question2'] = X_test['question2'].apply(remove_punct)\n",
    "X_test['question2'] = X_test['question2'].apply(stemmer)\n",
    "\n",
    "\n",
    "X_val['question1'] = X_val['question1'].apply(clean_text)\n",
    "X_val['question1'] = X_val['question1'].apply(remove_punct)\n",
    "X_val['question1'] = X_val['question1'].apply(stemmer)\n",
    "\n",
    "\n",
    "X_val['question2'] = X_val['question2'].apply(clean_text)\n",
    "X_val['question2'] = X_val['question2'].apply(remove_punct)\n",
    "X_val['question2'] = X_val['question2'].apply(stemmer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cXHuTzs_AqM3",
    "outputId": "c66fa605-fed6-43be-c566-143d31c3e448"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1713/1713 [00:20<00:00, 82.69it/s]\n",
      "100%|██████████| 1713/1713 [00:24<00:00, 69.44it/s]\n",
      "100%|██████████| 1713/1713 [00:22<00:00, 76.12it/s]\n",
      "100%|██████████| 1713/1713 [00:24<00:00, 70.04it/s]\n",
      "100%|██████████| 215/215 [00:03<00:00, 65.26it/s]\n",
      "100%|██████████| 215/215 [00:03<00:00, 56.68it/s]\n",
      "100%|██████████| 215/215 [00:02<00:00, 81.21it/s]\n",
      "100%|██████████| 215/215 [00:02<00:00, 71.74it/s]\n",
      "100%|██████████| 214/214 [00:02<00:00, 82.49it/s]\n",
      "100%|██████████| 214/214 [00:03<00:00, 70.91it/s]\n",
      "100%|██████████| 214/214 [00:02<00:00, 80.38it/s]\n",
      "100%|██████████| 214/214 [00:02<00:00, 75.41it/s]\n"
     ]
    }
   ],
   "source": [
    "entity_pairs_q1 = []\n",
    "for i in tqdm(X_train[\"question1\"]):\n",
    "    entity_pairs_q1.append(get_entities(i))\n",
    "relations_q1 = [get_relation(i) for i in tqdm(X_train['question1'])]\n",
    "\n",
    "\n",
    "entity_pairs_q2 = []\n",
    "for i in tqdm(X_train[\"question2\"]):\n",
    "    entity_pairs_q2.append(get_entities(i))\n",
    "relations_q2 = [get_relation(i) for i in tqdm(X_train['question2'])]\n",
    "\n",
    "\n",
    "entity_pairs_q1 = []\n",
    "for i in tqdm(X_test[\"question1\"]):\n",
    "    entity_pairs_q1.append(get_entities(i))\n",
    "relations_q1 = [get_relation(i) for i in tqdm(X_test['question1'])]\n",
    "\n",
    "\n",
    "entity_pairs_q2 = []\n",
    "for i in tqdm(X_test[\"question2\"]):\n",
    "    entity_pairs_q2.append(get_entities(i))\n",
    "relations_q2 = [get_relation(i) for i in tqdm(X_test['question2'])]\n",
    "\n",
    "\n",
    "\n",
    "entity_pairs_q1 = []\n",
    "for i in tqdm(X_val[\"question1\"]):\n",
    "    entity_pairs_q1.append(get_entities(i))\n",
    "relations_q1 = [get_relation(i) for i in tqdm(X_val['question1'])]\n",
    "\n",
    "\n",
    "entity_pairs_q2 = []\n",
    "for i in tqdm(X_val[\"question2\"]):\n",
    "    entity_pairs_q2.append(get_entities(i))\n",
    "relations_q2 = [get_relation(i) for i in tqdm(X_val['question2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "5pZeM3HCBFBs"
   },
   "outputs": [],
   "source": [
    "# Collect all tokens in a single list\n",
    "all_tokens = X_train['question1'].tolist() + X_train['question2'].tolist()\n",
    "all_tokens = X_test['question1'].tolist() + X_test['question2'].tolist()\n",
    "all_tokens = X_val['question1'].tolist() + X_val['question2'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "FwFa7PIZBGNv"
   },
   "outputs": [],
   "source": [
    "# Build vocabulary and convert words to indices\n",
    "word_to_idx = defaultdict(lambda: len(word_to_idx))\n",
    "data_indices = []\n",
    "for tokens in X_train['question1']:\n",
    "    indices = [word_to_idx[token] for token in tokens]\n",
    "    data_indices.append(indices)\n",
    "vocab_size = len(word_to_idx)\n",
    "\n",
    "\n",
    "# Build vocabulary and convert words to indices\n",
    "word_to_idx = defaultdict(lambda: len(word_to_idx))\n",
    "data_indices = []\n",
    "for tokens in X_test['question1']:\n",
    "    indices = [word_to_idx[token] for token in tokens]\n",
    "    data_indices.append(indices)\n",
    "vocab_size = len(word_to_idx)\n",
    "\n",
    "# Build vocabulary and convert words to indices\n",
    "word_to_idx = defaultdict(lambda: len(word_to_idx))\n",
    "data_indices = []\n",
    "for tokens in X_val['question1']:\n",
    "    indices = [word_to_idx[token] for token in tokens]\n",
    "    data_indices.append(indices)\n",
    "vocab_size = len(word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "KLydZyz5BKRa"
   },
   "outputs": [],
   "source": [
    "# Set Word2Vec parameters\n",
    "embed_dim = 100\n",
    "window_size = 5\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "vocab_size = len(word_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "_jhcV-oGBNrq"
   },
   "outputs": [],
   "source": [
    "# Initialize word embeddings randomly (with fixed seed for consistency)\n",
    "np.random.seed(42)\n",
    "word_embeddings = np.random.randn(vocab_size, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "XNaaiF9RBT6r"
   },
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "for _ in range(epochs):\n",
    "    for tokens in data_indices:\n",
    "        for target_idx, target_word in enumerate(tokens):\n",
    "            context_words = tokens[max(0, target_idx - window_size):target_idx] + \\\n",
    "                            tokens[target_idx + 1:min(target_idx + window_size + 1, len(tokens))]\n",
    "            for context_word in context_words:\n",
    "                target_idx_word = word_to_idx[target_word]\n",
    "                context_idx_word = word_to_idx[context_word]\n",
    "                if target_idx_word >= vocab_size or context_idx_word >= vocab_size:\n",
    "                    continue  # Skip if index is out of bounds\n",
    "                target_embed = word_embeddings[target_idx_word]\n",
    "                context_embed = word_embeddings[context_idx_word]\n",
    "                dot_product = np.dot(target_embed, context_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "yINXYa0TBXqA"
   },
   "outputs": [],
   "source": [
    "# Save the trained Word2Vec model\n",
    "np.save('word_embeddings.npy', word_embeddings)\n",
    "word_embeddings = np.load('word_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dW1jXLbsBc6g",
    "outputId": "7365a7ae-0406-4f02-abe1-e3470c02da9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "905     [0.1510997008792348, 0.17089837379908235, 0.02...\n",
       "1699    [-0.11648744061788212, 0.1266175660105227, -0....\n",
       "1954    [0.4625978591800741, -0.20425922480059427, 0.3...\n",
       "305     [0.17725748937794775, 0.2528124066385635, -0.0...\n",
       "986     [0.21721887840511928, -0.06711562830640486, -0...\n",
       "                              ...                        \n",
       "1638    [0.3475490213317623, 0.04845126722199611, 0.21...\n",
       "1095    [0.17655521014135322, 0.04088006056024692, 0.1...\n",
       "1130    [0.08715739223387636, 0.1839912319526426, 0.19...\n",
       "1294    [0.05885926849232315, 0.11879526923331765, -0....\n",
       "860     [-0.10401900321714036, -0.18364288017271044, 0...\n",
       "Name: question2_embedding, Length: 1713, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# تعريف دالة لحساب تضمين الجملة\n",
    "def sentence_embedding(tokens):\n",
    "    embeddings = [word_embeddings[word_to_idx[token]] for token in tokens if token in word_to_idx]\n",
    "    if embeddings:\n",
    "        embedding = np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        embedding = np.zeros(word_embeddings.shape[1])  # Return zeros if no valid embeddings found\n",
    "    return embedding\n",
    "\n",
    "X_train['question1_embedding'] = X_train['question1'].apply(sentence_embedding)\n",
    "X_train['question2_embedding'] = X_train['question2'].apply(sentence_embedding)\n",
    "\n",
    "X_train['question1_embedding']\n",
    "X_train['question2_embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gZqZsIYBf43",
    "outputId": "83fa4f36-ae83-4008-92b6-d6af6d2e3484"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "617     [0.10666870485125012, 0.20386688879160839, -0....\n",
       "1978    [0.3941859771722372, 0.18201523679711126, -0.0...\n",
       "554     [-0.0813540971357979, 0.0917351801106609, 0.12...\n",
       "940     [-0.07215703352556586, -0.20409082671345427, 0...\n",
       "49      [0.20657953381905914, 0.5904272190663447, -0.1...\n",
       "                              ...                        \n",
       "1999    [0.42070800943460473, -0.0741185291245811, 0.2...\n",
       "409     [-0.021816252409610295, 0.03487264574789953, -...\n",
       "610     [0.5275533926931878, -0.21267736591573633, 0.0...\n",
       "1380    [0.3365214021436171, 0.3863823254830411, 0.093...\n",
       "2114    [0.2753429346086572, 0.2901652063984354, 0.033...\n",
       "Name: question2_embedding, Length: 215, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# تعريف دالة لحساب تضمين الجملة\n",
    "def sentence_embedding(tokens):\n",
    "    embeddings = [word_embeddings[word_to_idx[token]] for token in tokens if token in word_to_idx]\n",
    "    if embeddings:\n",
    "        embedding = np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        embedding = np.zeros(word_embeddings.shape[1])  # Return zeros if no valid embeddings found\n",
    "    return embedding\n",
    "\n",
    "X_test['question1_embedding'] = X_test['question1'].apply(sentence_embedding)\n",
    "X_test['question2_embedding'] = X_test['question2'].apply(sentence_embedding)\n",
    "\n",
    "X_test['question1_embedding']\n",
    "X_test['question2_embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m78e-SlvBi5m",
    "outputId": "0693cf33-8740-430b-82c7-bcfc303e6ef8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1288    [-0.028019837295289615, 0.03233382078721756, 0...\n",
       "188     [0.2281793869117545, -0.033949403366445606, 0....\n",
       "1656    [-0.02897013637794444, -0.19598445636003875, 0...\n",
       "1657    [0.3332128178292566, -0.10104393672443691, 0.1...\n",
       "1677    [0.36144777879400347, -0.14200516363440546, 0....\n",
       "                              ...                        \n",
       "2118    [0.2330802275389303, -0.26177758367699455, 0.0...\n",
       "973     [0.24386459838863267, 0.25917381920274, -0.029...\n",
       "1607    [0.39112359435191374, -0.15792584986511846, 0....\n",
       "2069    [0.16275338620103819, 0.12785366649832297, -0....\n",
       "1177    [0.44722203441568686, 0.00364385227032315, 0.0...\n",
       "Name: question2_embedding, Length: 214, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# تعريف دالة لحساب تضمين الجملة\n",
    "def sentence_embedding(tokens):\n",
    "    embeddings = [word_embeddings[word_to_idx[token]] for token in tokens if token in word_to_idx]\n",
    "    if embeddings:\n",
    "        embedding = np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        embedding = np.zeros(word_embeddings.shape[1])  # Return zeros if no valid embeddings found\n",
    "    return embedding\n",
    "\n",
    "X_val['question1_embedding'] = X_val['question1'].apply(sentence_embedding)\n",
    "X_val['question2_embedding'] = X_val['question2'].apply(sentence_embedding)\n",
    "\n",
    "X_val['question1_embedding']\n",
    "X_val['question2_embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fubWn6qBnVQ",
    "outputId": "1e2d4684-9c28-4655-cf66-1b2c758dcfd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "905     0.957494\n",
      "1699    0.958355\n",
      "1954    0.917962\n",
      "305     0.974752\n",
      "986     0.908461\n",
      "          ...   \n",
      "1638    0.835898\n",
      "1095    0.901078\n",
      "1130    0.961082\n",
      "1294    0.946506\n",
      "860     0.963976\n",
      "Name: similarity_score, Length: 1713, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train['similarity_score'] = X_train.apply(lambda row: cosine_similarity([row['question1_embedding']], [row['question2_embedding']])[0][0], axis=1)\n",
    "\n",
    "print(X_train['similarity_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ommcm6PbBqNK",
    "outputId": "9ab0dc1c-b0ce-4dab-e39f-c12f14ca197b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617     0.819363\n",
      "1978    0.649163\n",
      "554     0.862549\n",
      "940     0.945272\n",
      "49      0.787175\n",
      "          ...   \n",
      "1999    0.869913\n",
      "409     0.906821\n",
      "610     0.893820\n",
      "1380    0.908749\n",
      "2114    0.976540\n",
      "Name: similarity_score, Length: 215, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_test['similarity_score'] = X_test.apply(lambda row: cosine_similarity([row['question1_embedding']], [row['question2_embedding']])[0][0], axis=1)\n",
    "\n",
    "print(X_test['similarity_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKwjmdy1BtEu",
    "outputId": "28d2614c-f11f-47cf-ef8b-2ec6658d5056"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288    0.882219\n",
      "188     0.840005\n",
      "1656    0.852874\n",
      "1657    0.800685\n",
      "1677    0.925080\n",
      "          ...   \n",
      "2118    0.976089\n",
      "973     0.956304\n",
      "1607    0.976213\n",
      "2069    0.858958\n",
      "1177    0.893975\n",
      "Name: similarity_score, Length: 214, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_val['similarity_score'] = X_val.apply(lambda row: cosine_similarity([row['question1_embedding']], [row['question2_embedding']])[0][0], axis=1)\n",
    "\n",
    "print(X_val['similarity_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "YPHXlHlMBwzk",
    "outputId": "e5ab541c-e9e2-4bb4-ce6c-c583c50e9a08"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>question1_embedding</th>\n",
       "      <th>question2_embedding</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>novo nordisk a s adr</td>\n",
       "      <td>novo nordisk asadr nvorepstg cl b sh</td>\n",
       "      <td>[0.20635870584842753, 0.20500242461882606, 0.0...</td>\n",
       "      <td>[0.1510997008792348, 0.17089837379908235, 0.02...</td>\n",
       "      <td>0.957494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>spdr barclay high yieldbond etf</td>\n",
       "      <td>spdr barclay high yield bond jnk</td>\n",
       "      <td>[0.022589573974845376, 0.14644783096810238, -0...</td>\n",
       "      <td>[-0.11648744061788212, 0.1266175660105227, -0....</td>\n",
       "      <td>0.958355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>freeport mcmoran copper and gold inc</td>\n",
       "      <td>freeportmcmoran inc</td>\n",
       "      <td>[0.19269153771819514, 0.004713147473101654, 0....</td>\n",
       "      <td>[0.4625978591800741, -0.20425922480059427, 0.3...</td>\n",
       "      <td>0.917962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>ishar msci switzerland cap</td>\n",
       "      <td>ishar msci switzerland cap etf</td>\n",
       "      <td>[0.1695486955523333, 0.30285200211500013, -0.0...</td>\n",
       "      <td>[0.17725748937794775, 0.2528124066385635, -0.0...</td>\n",
       "      <td>0.974752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>philip morri intern inc</td>\n",
       "      <td>philip morri intl com</td>\n",
       "      <td>[0.37357636172575287, -0.1982789870568978, -0....</td>\n",
       "      <td>[0.21721887840511928, -0.06711562830640486, -0...</td>\n",
       "      <td>0.908461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 question1  \\\n",
       "905                   novo nordisk a s adr   \n",
       "1699       spdr barclay high yieldbond etf   \n",
       "1954  freeport mcmoran copper and gold inc   \n",
       "305             ishar msci switzerland cap   \n",
       "986                philip morri intern inc   \n",
       "\n",
       "                                 question2  \\\n",
       "905   novo nordisk asadr nvorepstg cl b sh   \n",
       "1699      spdr barclay high yield bond jnk   \n",
       "1954                   freeportmcmoran inc   \n",
       "305         ishar msci switzerland cap etf   \n",
       "986                  philip morri intl com   \n",
       "\n",
       "                                    question1_embedding  \\\n",
       "905   [0.20635870584842753, 0.20500242461882606, 0.0...   \n",
       "1699  [0.022589573974845376, 0.14644783096810238, -0...   \n",
       "1954  [0.19269153771819514, 0.004713147473101654, 0....   \n",
       "305   [0.1695486955523333, 0.30285200211500013, -0.0...   \n",
       "986   [0.37357636172575287, -0.1982789870568978, -0....   \n",
       "\n",
       "                                    question2_embedding  similarity_score  \n",
       "905   [0.1510997008792348, 0.17089837379908235, 0.02...          0.957494  \n",
       "1699  [-0.11648744061788212, 0.1266175660105227, -0....          0.958355  \n",
       "1954  [0.4625978591800741, -0.20425922480059427, 0.3...          0.917962  \n",
       "305   [0.17725748937794775, 0.2528124066385635, -0.0...          0.974752  \n",
       "986   [0.21721887840511928, -0.06711562830640486, -0...          0.908461  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "IjfO2AoNBzZL",
    "outputId": "34c6600b-2aab-4155-f1b9-2d8c093e0c1b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>question1_embedding</th>\n",
       "      <th>question2_embedding</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>ld abt sh drtn inc i</td>\n",
       "      <td>lord abbett short durat incom fd cl f</td>\n",
       "      <td>[0.005559664379992879, 0.11024834883853671, -0...</td>\n",
       "      <td>[0.10666870485125012, 0.20386688879160839, -0....</td>\n",
       "      <td>0.819363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>trp retir</td>\n",
       "      <td>t row price fund</td>\n",
       "      <td>[0.6255601909267754, 0.5877591435893669, -0.54...</td>\n",
       "      <td>[0.3941859771722372, 0.18201523679711126, -0.0...</td>\n",
       "      <td>0.649163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>wp carey inc com</td>\n",
       "      <td>w p carey and co llc</td>\n",
       "      <td>[0.2521702597746931, -0.11624101786994645, 0.2...</td>\n",
       "      <td>[-0.0813540971357979, 0.0917351801106609, 0.12...</td>\n",
       "      <td>0.862549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>pimco incom fund cl d</td>\n",
       "      <td>pimco incm cl d</td>\n",
       "      <td>[0.04792427089015887, -0.20683349456724767, 0....</td>\n",
       "      <td>[-0.07215703352556586, -0.20409082671345427, 0...</td>\n",
       "      <td>0.945272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>prudenti jennison natur resourc z</td>\n",
       "      <td>pruj nat resrc z</td>\n",
       "      <td>[0.4362067059189712, 0.023848532097563956, 0.0...</td>\n",
       "      <td>[0.20657953381905914, 0.5904272190663447, -0.1...</td>\n",
       "      <td>0.787175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              question1  \\\n",
       "617                ld abt sh drtn inc i   \n",
       "1978                          trp retir   \n",
       "554                    wp carey inc com   \n",
       "940               pimco incom fund cl d   \n",
       "49    prudenti jennison natur resourc z   \n",
       "\n",
       "                                  question2  \\\n",
       "617   lord abbett short durat incom fd cl f   \n",
       "1978                       t row price fund   \n",
       "554                    w p carey and co llc   \n",
       "940                         pimco incm cl d   \n",
       "49                         pruj nat resrc z   \n",
       "\n",
       "                                    question1_embedding  \\\n",
       "617   [0.005559664379992879, 0.11024834883853671, -0...   \n",
       "1978  [0.6255601909267754, 0.5877591435893669, -0.54...   \n",
       "554   [0.2521702597746931, -0.11624101786994645, 0.2...   \n",
       "940   [0.04792427089015887, -0.20683349456724767, 0....   \n",
       "49    [0.4362067059189712, 0.023848532097563956, 0.0...   \n",
       "\n",
       "                                    question2_embedding  similarity_score  \n",
       "617   [0.10666870485125012, 0.20386688879160839, -0....          0.819363  \n",
       "1978  [0.3941859771722372, 0.18201523679711126, -0.0...          0.649163  \n",
       "554   [-0.0813540971357979, 0.0917351801106609, 0.12...          0.862549  \n",
       "940   [-0.07215703352556586, -0.20409082671345427, 0...          0.945272  \n",
       "49    [0.20657953381905914, 0.5904272190663447, -0.1...          0.787175  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "oDMWz8G4B2Lm",
    "outputId": "1286f08e-ab9b-46a0-ed85-44c783ef8649"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>question1_embedding</th>\n",
       "      <th>question2_embedding</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>blackrock total return fund cl a</td>\n",
       "      <td>blackrock glbl opp eq tr f growth incom fund</td>\n",
       "      <td>[0.023825259360543135, 0.03780456144526624, 0....</td>\n",
       "      <td>[-0.028019837295289615, 0.03233382078721756, 0...</td>\n",
       "      <td>0.882219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>energi transfer partner lp ut ltd</td>\n",
       "      <td>chenier energi partner lp com</td>\n",
       "      <td>[0.2797050908227616, 0.19915441360445904, -0.0...</td>\n",
       "      <td>[0.2281793869117545, -0.033949403366445606, 0....</td>\n",
       "      <td>0.840005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>facebook inc</td>\n",
       "      <td>facebook inc class a common stock</td>\n",
       "      <td>[0.07196725358664724, -0.530226979053655, 0.47...</td>\n",
       "      <td>[-0.02897013637794444, -0.19598445636003875, 0...</td>\n",
       "      <td>0.852874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>vang tot bd mk is pl</td>\n",
       "      <td>vanguard total bond market index inv</td>\n",
       "      <td>[0.03459463683253243, 0.11220642406583976, 0.0...</td>\n",
       "      <td>[0.3332128178292566, -0.10104393672443691, 0.1...</td>\n",
       "      <td>0.800685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>vanguard intl equiti index fd inc ftse allworl...</td>\n",
       "      <td>vanguard intl equiti index</td>\n",
       "      <td>[0.19024561963962633, -0.06739095178195993, -0...</td>\n",
       "      <td>[0.36144777879400347, -0.14200516363440546, 0....</td>\n",
       "      <td>0.925080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question1  \\\n",
       "1288                   blackrock total return fund cl a   \n",
       "188                   energi transfer partner lp ut ltd   \n",
       "1656                                       facebook inc   \n",
       "1657                               vang tot bd mk is pl   \n",
       "1677  vanguard intl equiti index fd inc ftse allworl...   \n",
       "\n",
       "                                         question2  \\\n",
       "1288  blackrock glbl opp eq tr f growth incom fund   \n",
       "188                  chenier energi partner lp com   \n",
       "1656             facebook inc class a common stock   \n",
       "1657          vanguard total bond market index inv   \n",
       "1677                    vanguard intl equiti index   \n",
       "\n",
       "                                    question1_embedding  \\\n",
       "1288  [0.023825259360543135, 0.03780456144526624, 0....   \n",
       "188   [0.2797050908227616, 0.19915441360445904, -0.0...   \n",
       "1656  [0.07196725358664724, -0.530226979053655, 0.47...   \n",
       "1657  [0.03459463683253243, 0.11220642406583976, 0.0...   \n",
       "1677  [0.19024561963962633, -0.06739095178195993, -0...   \n",
       "\n",
       "                                    question2_embedding  similarity_score  \n",
       "1288  [-0.028019837295289615, 0.03233382078721756, 0...          0.882219  \n",
       "188   [0.2281793869117545, -0.033949403366445606, 0....          0.840005  \n",
       "1656  [-0.02897013637794444, -0.19598445636003875, 0...          0.852874  \n",
       "1657  [0.3332128178292566, -0.10104393672443691, 0.1...          0.800685  \n",
       "1677  [0.36144777879400347, -0.14200516363440546, 0....          0.925080  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jlmcTiziB4qw",
    "outputId": "5ff59d19-a59f-40e2-d41a-9d9bb24fbcb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1713, 5), y_train shape: (1713,)\n",
      "X_test shape: (215, 5), y_test shape: (215,)\n",
      "X_val shape: (214, 5), y_val shape: (214,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "YwSDyaV1B7bK"
   },
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "\n",
    "y_pred = (X_train['similarity_score'] >= threshold).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TCz2YBHVB-Vj",
    "outputId": "6bbe495c-63df-4f73-ae37-4f5d73136401"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7553998832457677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VvO5rG3uC04i",
    "outputId": "2f5db8f0-2ec5-487d-f140-f888db5848f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[   0  419]\n",
      " [   0 1294]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3L76ZLKC6y7",
    "outputId": "30f55db4-a7d3-4774-97b1-5a941de652b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7553998832457677\n",
      "Recall: 1.0\n",
      "F1 Score: 0.8606584635849683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_train, y_pred)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "CnYae6hnDCMq"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "JL9nOpEhDIQP"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "batch_size = 32\n",
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "cz5BN7eiDK-L"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load your Word2Vec model\n",
    "word2vec_model = np.load('word_embeddings.npy')\n",
    "\n",
    "# Input layers for sentence embeddings\n",
    "input1 = Input(shape=(word2vec_model.shape[1],))  # Assuming the shape is (num_words, vector_size)\n",
    "input2 = Input(shape=(word2vec_model.shape[1],))\n",
    "\n",
    "# Dense layers\n",
    "dense1 = Dense(15, activation='relu')(input1)\n",
    "dense2 = Dense(15, activation='relu')(input2)\n",
    "\n",
    "# Concatenate and output\n",
    "concat = Concatenate()([dense1, dense2])\n",
    "output = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B9s1cbxYDrc2",
    "outputId": "5f5feb89-8bae-4a92-8458-973488367791"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m6,432\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m2,112\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,609</span> (33.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,609\u001b[0m (33.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,609</span> (33.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,609\u001b[0m (33.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Concatenate, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Preprocess your data\n",
    "X_train_X1 = np.array(X_train['question1_embedding'].tolist())\n",
    "X_train_X2 = np.array(X_train['question2_embedding'].tolist())\n",
    "X_train_y = X_train['similarity_score'].values\n",
    "\n",
    "X_test_X1 = np.array(X_test['question1_embedding'].tolist())\n",
    "X_test_X2 = np.array(X_test['question2_embedding'].tolist())\n",
    "X_test_y = X_test['similarity_score'].values\n",
    "\n",
    "\n",
    "\n",
    "# Define input shapes\n",
    "input_dim = X_train_X1.shape[1]\n",
    "\n",
    "input_shape = (input_dim,)  # Define your input dimension\n",
    "\n",
    "# Define inputs\n",
    "input1 = Input(shape=input_shape)\n",
    "input2 = Input(shape=input_shape)\n",
    "\n",
    "# Concatenate the inputs\n",
    "concatenated = Concatenate(axis=-1)([input1, input2])\n",
    "\n",
    "# Add dense layers for processing\n",
    "dense1 = Dense(32, activation='relu')(concatenated)\n",
    "dense2 = Dense(64, activation='relu')(dense1)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(1, activation='sigmoid')(dense2)  # Output similarity score between 0 and 1\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qd-gjHcEG7ng",
    "outputId": "e66d98f5-071e-49de-b1cf-f15f5210eb0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7755 - loss: 0.4825 - val_accuracy: 0.8560 - val_loss: 0.3833\n",
      "Epoch 2/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8509 - loss: 0.3539 - val_accuracy: 0.8482 - val_loss: 0.3694\n",
      "Epoch 3/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8702 - loss: 0.3195 - val_accuracy: 0.8638 - val_loss: 0.3423\n",
      "Epoch 4/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8602 - loss: 0.3046 - val_accuracy: 0.8755 - val_loss: 0.3328\n",
      "Epoch 5/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8675 - loss: 0.2846 - val_accuracy: 0.8755 - val_loss: 0.3426\n",
      "Epoch 6/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8800 - loss: 0.2921 - val_accuracy: 0.8872 - val_loss: 0.3378\n",
      "Epoch 7/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8919 - loss: 0.2404 - val_accuracy: 0.8638 - val_loss: 0.3442\n",
      "Epoch 8/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9045 - loss: 0.2383 - val_accuracy: 0.8755 - val_loss: 0.3333\n",
      "Epoch 9/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9153 - loss: 0.2087 - val_accuracy: 0.8677 - val_loss: 0.3483\n",
      "Epoch 10/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9197 - loss: 0.2074 - val_accuracy: 0.8677 - val_loss: 0.3411\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8726 - loss: 0.2592 \n",
      "Test Accuracy: 0.8790697455406189\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have your training data X_train_X1, X_train_X2, and y_train ready\n",
    "\n",
    "# Train the model\n",
    "history = model.fit([X_train_X1, X_train_X2], y_train, batch_size=32, epochs=10, validation_split=0.15)\n",
    "\n",
    "# After training, you can evaluate the model on test data\n",
    "# Assuming you have your test data X_test_X1, X_test_X2, and y_test ready\n",
    "test_loss, test_accuracy = model.evaluate([X_test_X1, X_test_X2], y_test)\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd250553d3f47b1816aa2863f778aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Dell\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e1a1b4385749e0a5e8c1052e64952b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1edb31c2ac4a7a87d725754daf1e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebaf8f0612f84a92afc04a6869015889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88aa649baec4808b987e8871a4a5463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f35734e2e304ec9b56fa0d9b400009f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99f95367e7a418888faeee81e4a6c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2c99e9a3a34774995db5f9852641a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0487d3533d0740fe8bd530cdbf3094de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5299a7303afb4aecac631d10156ff9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e6594ef0fb45eda7ea05168d65317f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train similarity scores:\n",
      "tensor([[0.7018, 0.2973, 0.1653,  ..., 0.2056, 0.0700, 0.2535],\n",
      "        [0.2019, 0.6900, 0.1422,  ..., 0.3246, 0.2457, 0.1732],\n",
      "        [0.0416, 0.1317, 0.6836,  ..., 0.1339, 0.2495, 0.3050],\n",
      "        ...,\n",
      "        [0.1457, 0.2064, 0.2192,  ..., 0.8122, 0.2044, 0.0628],\n",
      "        [0.1005, 0.1698, 0.3280,  ..., 0.1996, 0.9487, 0.2687],\n",
      "        [0.2318, 0.1039, 0.3361,  ..., 0.0121, 0.2936, 0.9278]])\n",
      "Validation similarity scores:\n",
      "tensor([[0.7332, 0.1041, 0.3396,  ..., 0.2722, 0.4743, 0.2650],\n",
      "        [0.1931, 0.7105, 0.0591,  ..., 0.1371, 0.2825, 0.1589],\n",
      "        [0.3465, 0.2227, 0.6957,  ..., 0.2318, 0.1575, 0.2098],\n",
      "        ...,\n",
      "        [0.2865, 0.1340, 0.1673,  ..., 0.8443, 0.2782, 0.0595],\n",
      "        [0.3804, 0.2179, 0.1466,  ..., 0.1237, 0.6755, 0.2934],\n",
      "        [0.1976, 0.0712, 0.0762,  ..., 0.1004, 0.1356, 0.2642]])\n",
      "Test similarity scores:\n",
      "tensor([[0.4027, 0.0945, 0.3054,  ..., 0.2119, 0.2871, 0.1614],\n",
      "        [0.2150, 0.2298, 0.2499,  ..., 0.2630, 0.2581, 0.1638],\n",
      "        [0.0399, 0.2174, 0.7978,  ..., 0.1195, 0.0374, 0.0586],\n",
      "        ...,\n",
      "        [0.2526, 0.1949, 0.1970,  ..., 0.4058, 0.2306, 0.2846],\n",
      "        [0.1927, 0.2858, 0.2535,  ..., 0.2796, 0.7549, 0.3777],\n",
      "        [0.2073, 0.2311, 0.1378,  ..., 0.2584, 0.3756, 0.9092]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "# Function to compute embeddings and cosine similarity scores\n",
    "def compute_similarity_scores(model, question_pairs):\n",
    "    embeddings1 = model.encode(question_pairs['question1'].tolist(), convert_to_tensor=True)\n",
    "    embeddings2 = model.encode(question_pairs['question2'].tolist(), convert_to_tensor=True)\n",
    "    cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    return cosine_scores\n",
    "# Compute similarity scores for the training set\n",
    "train_scores = compute_similarity_scores(model, X_train)\n",
    "print(f\"Train similarity scores:\\n{train_scores}\")\n",
    "\n",
    "# Compute similarity scores for the validation set\n",
    "val_scores = compute_similarity_scores(model, X_val)\n",
    "print(f\"Validation similarity scores:\\n{val_scores}\")\n",
    "\n",
    "# Compute similarity scores for the test set\n",
    "test_scores = compute_similarity_scores(model, X_test)\n",
    "print(f\"Test similarity scores:\\n{test_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7904261529480444\n",
      "Precision: 0.8157\n",
      "Recall: 0.9335\n",
      "F1 Score: 0.8706\n"
     ]
    }
   ],
   "source": [
    "# Define a threshold for similarity scores\n",
    "\n",
    "def convert_to_predictions(scores, threshold):\n",
    "    predictions = []\n",
    "    for score_list in scores:\n",
    "        # Calculate the average similarity score for each pair\n",
    "        avg_score = sum(score_list) / len(score_list)\n",
    "        # Convert the average score to a binary prediction\n",
    "        prediction = 1 if avg_score >= threshold else 0\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Convert cosine_scores to binary predictions based on the chosen threshold\n",
    "threshold = 0.5  # Adjust this threshold based on your validation set\n",
    "binary_predictions = (train_scores.diag() > threshold).int()\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "accuracy = accuracy_score(y_train, binary_predictions)\n",
    "precision = precision_score(y_train, binary_predictions)\n",
    "recall = recall_score(y_train, binary_predictions)\n",
    "f1 = f1_score(y_train, binary_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7488372093023256\n",
      "Precision: 0.7903\n",
      "Recall: 0.9074\n",
      "F1 Score: 0.8448\n"
     ]
    }
   ],
   "source": [
    "# Define a threshold for similarity scores\n",
    "\n",
    "def convert_to_predictions(scores, threshold):\n",
    "    predictions = []\n",
    "    for score_list in scores:\n",
    "        # Calculate the average similarity score for each pair\n",
    "        avg_score = sum(score_list) / len(score_list)\n",
    "        # Convert the average score to a binary prediction\n",
    "        prediction = 1 if avg_score >= threshold else 0\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Convert cosine_scores to binary predictions based on the chosen threshold\n",
    "threshold = 0.5  # Adjust this threshold based on your validation set\n",
    "test_binary_predictions = (test_scores.diag() > threshold).int()\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "accuracy = accuracy_score(y_test, test_binary_predictions)\n",
    "precision = precision_score(y_test, test_binary_predictions)\n",
    "recall = recall_score(y_test, test_binary_predictions)\n",
    "f1 = f1_score(y_test, test_binary_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog\n",
    "\n",
    "# Load your Word2Vec model\n",
    "word_embeddings = np.load('word_embeddings.npy')\n",
    "\n",
    "# Function to find the most similar words (dummy function for illustration)\n",
    "def find_similar_words(word):\n",
    "    # Your logic to find similar words goes here\n",
    "    # For now, it just returns a dummy list\n",
    "    return [\"word1\", \"word2\", \"word3\"]\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Word2Vec GUI\")\n",
    "\n",
    "# Add an entry field\n",
    "entry = tk.Entry(root)\n",
    "entry.pack()\n",
    "\n",
    "# Function to handle button click\n",
    "def on_button_click():\n",
    "    word = entry.get()\n",
    "    similar_words = find_similar_words(word)\n",
    "    result_label.config(text=\"\\n\".join(similar_words))\n",
    "\n",
    "# Add a button\n",
    "button = tk.Button(root, text=\"Find Similar Words\", command=on_button_click)\n",
    "button.pack()\n",
    "\n",
    "# Add a label to display results\n",
    "result_label = tk.Label(root, text=\"\")\n",
    "result_label.pack()\n",
    "\n",
    "# Run the application\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from collections import defaultdict  # Import defaultdict to use in text_to_index\n",
    "\n",
    "# Load the numpy array of word embeddings (replace 'word_embeddings.npy' with your file path)\n",
    "word_embeddings = np.load('word_embeddings.npy')\n",
    "\n",
    "# Dummy function to convert text to indices (you'll need to implement this)\n",
    "def text_to_index(text):\n",
    "    word_to_idx = defaultdict(lambda: len(word_to_idx))\n",
    "    data_indices = []\n",
    "    for tokens in X_train['question1']:\n",
    "        indices = [word_to_idx[token] for token in tokens]\n",
    "        data_indices.append(indices)\n",
    "    vocab_size = len(word_to_idx)\n",
    "    return hash(text) % len(word_embeddings)\n",
    "\n",
    "\n",
    "# Function to calculate sentence similarity\n",
    "def calculate_similarity():\n",
    "    text1 = entry1.get()\n",
    "    text2 = entry2.get()\n",
    "    \n",
    "    # Convert the input sentences into indices\n",
    "    index1 = text_to_index(text1)\n",
    "    index2 = text_to_index(text2)\n",
    "    \n",
    "    # Retrieve embeddings for the indices\n",
    "    embedding1 = word_embeddings[index1]\n",
    "    embedding2 = word_embeddings[index2]\n",
    "    \n",
    "    # Calculate cosine similarity between the vectors\n",
    "    similarity_score = 1 - cosine(embedding1, embedding2)\n",
    "    \n",
    "    # Display the similarity score\n",
    "    output_text.delete(1.0, tk.END)\n",
    "    output_text.insert(tk.END, f\"Similarity Score: {similarity_score:.4f}\")\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Sentence Similarity Model GUI\")\n",
    "\n",
    "# Create input fields\n",
    "label1 = ttk.Label(root, text=\"Input 1:\")\n",
    "label1.grid(row=0, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "entry1 = ttk.Entry(root, width=40)\n",
    "entry1.grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "label2 = ttk.Label(root, text=\"Input 2:\")\n",
    "label2.grid(row=1, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "entry2 = ttk.Entry(root, width=40)\n",
    "entry2.grid(row=1, column=1, padx=5, pady=5)\n",
    "\n",
    "# Create button to trigger similarity calculation\n",
    "calculate_button = ttk.Button(root, text=\"Calculate Similarity\", command=calculate_similarity)\n",
    "calculate_button.grid(row=2, column=0, columnspan=2, padx=5, pady=5)\n",
    "\n",
    "# Create output field\n",
    "output_text = tk.Text(root, height=2, width=50)\n",
    "output_text.grid(row=3, column=0, columnspan=2, padx=5, pady=5)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
